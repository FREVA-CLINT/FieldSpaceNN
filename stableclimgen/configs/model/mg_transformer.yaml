_target_: stableclimgen.src.models.mg_transformer.pl_mg_model.LightningMGModel
decomposed_loss: true
lambda_loss_dict:
  MSE_loss: 1
  NH_loss: 0
weight_decay: 0
lr_groups:
  default:
    lr: 5e-4
    warmup: 0
  attention:
    matches: ['TransformerBlock','GridSelfAttention']
    lr: 5e-4
    warmup: 500
model:
  _target_: stableclimgen.src.models.mg_transformer.mg_transformer.MG_Transformer
  mgrids: ${mgrids}
  mg_emb_confs: ${embedding.MGEmbedder.mg_emb_confs}
  in_zooms: [4,6]
  in_features: 2
  out_features: 2
  lift_features: 1
  n_head_channels: 15
  learn_residual: false
  with_global_gamma: false
  use_mask: true
  layer_confs_emb:
    n_groups: 1
  block_configs:
    "input":
      _target_: stableclimgen.src.modules.multi_grid.confs.MGProcessingConfig
      out_features: [128,128,128]
      zooms: [4,6]
      layer_settings:
        type: 'linear'
    "0":
      _target_: stableclimgen.src.modules.multi_grid.confs.MGProcessingConfig
      out_features: [128,128]
      zooms: [4,6]
      layer_settings:
        type: "TransformerBlock"
        blocks: ["t","mlp","vsnh","mlp"]
        seq_lengths: [10,2]
        n_head_channels: 32
        mlp_mult: 2
        embed_confs:
          embed_names:
            - ["MGEmbedder"]
            - ["MGEmbedder"]
            - ["MGEmbedder"]
            - ["MGEmbedder"]
          embed_confs: ${embedding}
          embed_mode: "sum"
    "8":
      _target_: stableclimgen.src.modules.multi_grid.confs.MGSelfProcessingConfig
      out_features: 128
      q_zooms: [4,6]
      kv_zooms: [4,6]
      layer_settings:
        with_nh: true
        common_kv: false
        n_head_channels: 32
        mlp_mult: 2
        embed_confs:
          embed_names: [ "MGEmbedder"]
          embed_confs: ${embedding}
          embed_mode: "sum"
    "output":
      _target_: stableclimgen.src.modules.multi_grid.confs.MGProcessingConfig
      out_features: [2,2]
      zooms: [4,6]
      layer_settings:
        type: 'mlp'